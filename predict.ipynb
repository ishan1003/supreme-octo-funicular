{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_from_step.py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# your pieces\n",
    "# from dataset_loader import build_node_features   # uses scalar \"type\" (D=10)\n",
    "from convert_step_to_graph import convert_step_to_graph     # <-- adjust import if named differently\n",
    "\n",
    "# label names (used if not embedded in the checkpoint)\n",
    "FEAT_NAMES_DEFAULT = ['chamfer', 'through_hole', 'triangular_passage', 'rectangular_passage', '6sides_passage',\n",
    "                      'triangular_through_slot', 'rectangular_through_slot', 'circular_through_slot',\n",
    "                      'rectangular_through_step', '2sides_through_step', 'slanted_through_step', 'Oring', 'blind_hole',\n",
    "                      'triangular_pocket', 'rectangular_pocket', '6sides_pocket', 'circular_end_pocket',\n",
    "                      'rectangular_blind_slot', 'v_circular_end_blind_slot', 'h_circular_end_blind_slot',\n",
    "                      'triangular_blind_step', 'circular_blind_step', 'rectangular_blind_step', 'round', 'stock']\n",
    "\n",
    "NUM_CLASSES = 25\n",
    "\n",
    "# same tiny GCN as training\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=128, out_dim=NUM_CLASSES, dropout=0.2):\n",
    "        super().__init__()\n",
    "        from torch_geometric.nn import GCNConv\n",
    "        self.c1 = GCNConv(in_dim, hidden)\n",
    "        self.c2 = GCNConv(hidden, hidden)\n",
    "        self.lin = nn.Linear(hidden, out_dim)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.c1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.c2(x, edge_index))\n",
    "        return self.lin(x)\n",
    "\n",
    "def _load_model(ckpt_path: str | Path, device: torch.device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    in_dim       = int(ckpt.get(\"in_dim\", 10))\n",
    "    hidden       = int(ckpt.get(\"hidden\", 128))\n",
    "    num_classes  = int(ckpt.get(\"num_classes\", NUM_CLASSES))\n",
    "    feat_names   = ckpt.get(\"feat_names\", FEAT_NAMES_DEFAULT)\n",
    "    state_dict   = ckpt[\"state_dict\"]\n",
    "\n",
    "    model = GCN(in_dim, hidden=hidden, out_dim=num_classes).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model, feat_names\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_from_step(\n",
    "    step_path: str | Path,\n",
    "    ckpt_path: str | Path = \"./checkpoints/gcn_facecls.pt\",\n",
    "    device: str | torch.device | None = None,\n",
    "    extractor_kwargs: dict | None = None,\n",
    "    use_amp: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        'labels_idx':  [num_faces] int list,\n",
    "        'labels_name': [num_faces] str list,\n",
    "        'num_faces':   int\n",
    "      }\n",
    "    \"\"\"\n",
    "    step_path = Path(step_path)\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    elif isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "    extractor_kwargs = extractor_kwargs or {}\n",
    "\n",
    "    # 1) STEP -> graph (we only need face_features + edge_index)\n",
    "    # tip: to speed up, you can pass n_samples_proximity=16 or even 0 if you made that safe\n",
    "    extractor = BRepGraphExtractor(str(step_path), **extractor_kwargs)\n",
    "    graph = extractor.extract_features()\n",
    "\n",
    "    # 2) Build node features exactly like training (scalar 'type')\n",
    "    x_np = build_node_features(graph[\"face_features\"], use_type_onehot=False)  # shape [N,10]\n",
    "    ei_np = np.asarray(graph[\"edge_index\"], dtype=np.int64)                    # shape [2,E]\n",
    "    x  = torch.from_numpy(x_np).to(device)\n",
    "    ei = torch.from_numpy(ei_np).to(device)\n",
    "\n",
    "    # 3) Load model\n",
    "    model, feat_names = _load_model(ckpt_path, device)\n",
    "\n",
    "    # 4) Predict\n",
    "    if device.type == \"cuda\" and use_amp:\n",
    "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "            logits = model(x, ei)\n",
    "    else:\n",
    "        logits = model(x, ei)\n",
    "\n",
    "    pred_idx = logits.argmax(dim=1).tolist()\n",
    "    pred_names = [feat_names[i] for i in pred_idx]\n",
    "\n",
    "    return {\"labels_idx\": pred_idx, \"labels_name\": pred_names, \"num_faces\": len(pred_idx)}\n",
    "\n",
    "# --- example ---\n",
    "if __name__ == \"__main__\":\n",
    "    res = predict_from_step(\n",
    "        step_path=\"./dataset/dataset_generation/data/0.stp\",\n",
    "        ckpt_path=\"./checkpoints/gcn_facecls.pt\",\n",
    "        device=\"cuda\",\n",
    "        extractor_kwargs={\"n_samples_proximity\": 16},  # faster; not used by the model anyway\n",
    "    )\n",
    "    print(\"faces:\", res[\"num_faces\"])\n",
    "    print(res[\"labels_name\"][:20], \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
